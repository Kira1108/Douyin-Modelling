{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huan/anaconda/envs/py3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from item_embedding import item_encode\n",
    "from preprocess_user import make_user_fans_pipeline\n",
    "from etl import load_user_info_features\n",
    "from etl import load_fans_info_features\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score,accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.layers import Input, Embedding, Dot, Add,Flatten,Dense,Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdf(data):\n",
    "    return np.sort(data), np.arange(1, len(data) + 1) / len(data)\n",
    "\n",
    "\n",
    "def get_live_goods():\n",
    "    '''Simply get live goods\n",
    "    '''\n",
    "    conn = pymysql.connect(host = '127.0.0.1', \n",
    "                       user = 'root', \n",
    "                       password = 'root123', \n",
    "                       db = 'delidou')\n",
    "\n",
    "    live_goods = pd.read_sql_query('''\n",
    "        select g.* from base_live_goods g\n",
    "        inner join(\n",
    "            select distinct u.id as uid from base_user_info u\n",
    "            inner join(\n",
    "                select id from base_user_fans\n",
    "            ) f on u.id = f.id\n",
    "        ) uf on g.id = uf.uid\n",
    "    ''', conn)\n",
    "    \n",
    "    live_goods = live_goods.rename(columns = {'goods_id':'link_id'})\n",
    "    \n",
    "    return live_goods\n",
    "\n",
    "\n",
    "def resample_goods(goods, neg_pos_ratio = 3):\n",
    "    '''Sample to a resonable negtive to positive ratio'''\n",
    "    \n",
    "    positive = goods[goods.sales_count > 0]\n",
    "    negative = goods[goods.sales_count == 0]\n",
    "    neg_ids = np.random.choice(len(negative), size = len(positive) * neg_pos_ratio,replace = False)\n",
    "    negative = negative.iloc[neg_ids,:]\n",
    "    df = pd.concat([positive, negative],sort = False)\n",
    "    df['sales_count_log1p'] = np.log1p(df['sales_count'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0822 18:58:50.437219 4633406912 __init__.py:111] Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/jh/q3qgwx4n59b_rg88dkbcb20m0000gn/T/jieba.cache\n",
      "I0822 18:58:50.439434 4633406912 __init__.py:131] Loading model from cache /var/folders/jh/q3qgwx4n59b_rg88dkbcb20m0000gn/T/jieba.cache\n",
      "Loading model cost 0.606 seconds.\n",
      "I0822 18:58:51.044929 4633406912 __init__.py:163] Loading model cost 0.606 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "I0822 18:58:51.046490 4633406912 __init__.py:164] Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# get goods\n",
    "live_goods = get_live_goods()\n",
    "live_goods = resample_goods(live_goods,1)\n",
    "\n",
    "# get item encode\n",
    "encoded_items,live_goods = item_encode(live_goods)\n",
    "\n",
    "# parameters\n",
    "n_users = live_goods['id'].nunique()\n",
    "n_items = live_goods.link_id.nunique()\n",
    "n_pref = live_goods.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 2498\n",
      "Number of items: 73754\n",
      "Number of records: 213718\n"
     ]
    }
   ],
   "source": [
    "print('Number of users: {}'.format(n_users))\n",
    "print('Number of items: {}'.format(n_items))\n",
    "print('Number of records: {}'.format(n_pref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_goods_live():\n",
    "    '''\n",
    "        Get goods data\n",
    "        Encode goods to vectors\n",
    "        \n",
    "        Parameters:\n",
    "        \n",
    "        Returns:\n",
    "            encoded_items: (N_items, item_embedding_dimension)\n",
    "            goods: goods dataframe\n",
    "    '''\n",
    "    conn = pymysql.connect(host = '127.0.0.1', \n",
    "                       user = 'root', \n",
    "                       password = 'root123', \n",
    "                       db = 'delidou')\n",
    "    \n",
    "    # \n",
    "    goods = pd.read_sql_query('''\n",
    "        select g.id as id, goods_id as link_id, g.name, g.tag  from base_live_goods g\n",
    "        inner join(\n",
    "            select distinct u.id as uid from base_user_info u\n",
    "            inner join(\n",
    "                select id from base_user_fans\n",
    "            ) f on u.id = f.id\n",
    "        ) uf on g.id = uf.uid\n",
    "    ''', conn)\n",
    "    \n",
    "    \n",
    "    encoded_items,goods = item_encode(goods)\n",
    "    goods = goods.reset_index(drop = True)\n",
    "    \n",
    "    n_users = goods['id'].nunique()\n",
    "    n_items = goods.link_id.nunique()\n",
    "    n_pref = goods.shape[0]\n",
    "\n",
    "    print('Number of users: {}'.format(n_users))\n",
    "    print('Number of items: {}'.format(n_items))\n",
    "    print('Number of records: {}'.format(n_pref))\n",
    "    \n",
    "    return encoded_items, goods\n",
    "\n",
    "\n",
    "def filter_goods_and_users(goods, user_n_item = 10, item_n_user = 10):\n",
    "    '''\n",
    "        Select top users and items\n",
    "    '''\n",
    "    \n",
    "    item_count = goods.groupby('link_id')['id']\\\n",
    "        .agg(lambda x:len(set(x))).reset_index()\\\n",
    "        .sort_values(by = 'id',ascending = False)\n",
    "    \n",
    "    top_link_ids = item_count[item_count.id > item_n_user].link_id.values\n",
    "    \n",
    "    user_count = goods.groupby('id')['link_id']\\\n",
    "        .agg(lambda x:len(set(x))).reset_index()\\\n",
    "        .sort_values(by = 'link_id',ascending = False)\n",
    "    \n",
    "    top_user_ids = user_count[user_count.link_id > user_n_item].id.values\n",
    "    \n",
    "    goods = goods[(goods.id.isin(top_user_ids)) & (goods.link_id.isin(top_link_ids))]\n",
    "    # goods = goods[(goods.id.isin(top_user_ids)) & (goods.link_id.isin(top_link_ids)) & (goods.id.isin(user_fans.id.values))]\n",
    "    \n",
    "    return goods,top_link_ids, top_user_ids\n",
    "\n",
    "\n",
    "\n",
    "def load_user_features(n_regions = 30):\n",
    "    \n",
    "    '''Load user and fans data, process using predefined pipeline'''\n",
    "    \n",
    "    user = load_user_info_features()\n",
    "    fans = load_fans_info_features()\n",
    "    user_fans = user.merge(fans, on = 'id', how = 'inner')\n",
    "    pipe = make_user_fans_pipeline(n_regions)\n",
    "    user_features = pipe.fit_transform(user_fans)\n",
    "    return user_features, user_fans\n",
    "\n",
    "\n",
    "\n",
    "def userinfo_to_id(user_features, user_fans, user2id):\n",
    "    result = []\n",
    "    for user, f  in zip(user_fans.id.values, user_features):\n",
    "        if user in user2id.keys():\n",
    "            result.append([user2id[user],*f])\n",
    "\n",
    "    user_features = pd.DataFrame(result)\n",
    "    user_features.columns = ['user_id' if col == 0 else 'F_' + str(col) for col in user_features]\n",
    "    user_features = user_features.iloc[:,1:]\n",
    "    return user_features\n",
    "\n",
    "\n",
    "\n",
    "def make_rating_table(goods):\n",
    "    '''\n",
    "        Make a 3 column rating table\n",
    "    '''\n",
    "    ratings = goods[['id','link_id']].copy()\n",
    "    ratings['rating'] = 1\n",
    "    ratings = ratings.rename(columns = {'id':'user_id','link_id':'item_id'})\n",
    "    user2id = {user:i for i, user in enumerate(ratings.user_id.unique())}\n",
    "    item2id = {item:i for i, item in enumerate(ratings.item_id.unique())}\n",
    "    ratings['user_id'] = ratings['user_id'].replace(user2id)\n",
    "    ratings['item_id'] = ratings['item_id'].replace(item2id)\n",
    "    return ratings, user2id, item2id\n",
    "\n",
    "\n",
    "\n",
    "def negative_sampling(ratings, n_negative = 50):\n",
    "    '''\n",
    "        Negative sampling\n",
    "    '''\n",
    "    all_items = set(ratings.item_id.unique())\n",
    "    negative_samples = []\n",
    "    for user_id in ratings.user_id.unique():\n",
    "        user_items = set(ratings[ratings.user_id == user_id]['item_id'].tolist())\n",
    "        space = list(all_items.difference(set(user_items)))\n",
    "        neg_items = np.random.choice(space, size = n_negative)\n",
    "        for neg_item in neg_items:\n",
    "            negative_samples.append([user_id, neg_item,0])\n",
    "    neg_ratings = pd.DataFrame(negative_samples,columns = ['user_id','item_id','rating'])\n",
    "    dataset = pd.concat([ratings, neg_ratings])\n",
    "    return dataset\n",
    "\n",
    "\n",
    "\n",
    "def recommend_train_test_split(dataset, encoded_items, user_features, \n",
    "                               test_size = 0.1, shuffle = True):\n",
    "    \n",
    "    X_train, X_test, y_train,y_test =  train_test_split(dataset[['user_id','item_id']], \n",
    "                                                    dataset['rating'], \n",
    "                                                    test_size = 0.1, \n",
    "                                                    shuffle = True)\n",
    "\n",
    "    item_encode_train = encoded_items[X_train.item_id.values]\n",
    "    item_encode_test = encoded_items[X_test.item_id.values]\n",
    "    \n",
    "    user_feature_train = user_features.iloc[X_train.user_id.values,:]\n",
    "    user_feature_test = user_features.iloc[X_test.user_id.values,:]\n",
    "    \n",
    "    \n",
    "    print_info = '''\n",
    "    ======================================\n",
    "    Dataset Summary:\n",
    "    ======================================\n",
    "    X_train: {}\n",
    "    X_test: {}\n",
    "    item_encode_train: {}\n",
    "    item_encode_test: {}\n",
    "    user_feature_train: {}\n",
    "    user_features_test: {}\n",
    "    ======================================\n",
    "    '''.format(X_train.shape, X_test.shape, \n",
    "               item_encode_train.shape, item_encode_test.shape, \n",
    "               user_feature_train.shape, user_feature_test.shape)\n",
    "    \n",
    "    print(print_info)\n",
    "    \n",
    "    return X_train, item_encode_train, user_feature_train,\\\n",
    "            X_test, item_encode_test, user_feature_test,y_train, y_test\n",
    "\n",
    "\n",
    "def get_recommend_model(n_users, n_items, item_feature_dim, user_feature_dim, embed_hidden_dim = 10, reg = 0.):\n",
    "    \n",
    "    user_input = Input(1,)\n",
    "    item_input = Input(1,)\n",
    "    encoded_items_tensor = Input(item_feature_dim,)\n",
    "    input_user_feature = Input(user_feature_dim,)\n",
    "\n",
    "    user_embedding = Embedding(n_users,embed_hidden_dim, embeddings_regularizer=l2(reg))(user_input)\n",
    "    item_embedding = Embedding(n_items,embed_hidden_dim, embeddings_regularizer=l2(reg))(item_input)\n",
    "\n",
    "    user_bias = Embedding(n_users,1, embeddings_regularizer=l2(reg))(user_input)\n",
    "    item_bias = Embedding(n_items,1, embeddings_regularizer=l2(reg))(item_input)\n",
    "\n",
    "    rating_pred = Dot(axes = 2)([user_embedding, item_embedding])\n",
    "    rating_pred = Add()([rating_pred, user_bias, item_bias])\n",
    "    rating_pred = Flatten()(rating_pred)\n",
    "    rating_pred = Concatenate()([rating_pred,encoded_items_tensor,input_user_feature])\n",
    "    rating_pred = Dense(16, activation = 'relu')(rating_pred)\n",
    "    rating_pred = Dense(1, activation = 'sigmoid')(rating_pred)\n",
    "\n",
    "    model = Model([user_input, item_input,encoded_items_tensor,input_user_feature],rating_pred)\n",
    "        \n",
    "    model.compile(optimizer = Adam(lr = 0.001),loss = tf.keras.losses.BinaryCrossentropy(),metrics = ['accuracy'])\n",
    "    return model\n",
    "    \n",
    "    \n",
    "def evaluate_model(model, X_test, item_encode_test, user_feature_test,y_test):\n",
    "    \n",
    "    # predict\n",
    "    preds = (model.predict(x = [X_test.user_id.values,\n",
    "                                X_test.item_id.values,\n",
    "                                item_encode_test, \n",
    "                                user_feature_test]) > 0.5).flatten()\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, preds)\n",
    "    fig, ax = plt.subplots(figsize = (6,4))\n",
    "    sns.heatmap(confuse / confuse.sum(), annot = True)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    auc = roc_auc_score(y_test, preds)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    print('Accuracy Score: {}'.format(acc))\n",
    "    print('Auc score: {}'.format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 2515\n",
      "Number of items: 91461\n",
      "Number of records: 346134\n",
      "\n",
      "    ======================================\n",
      "    Dataset Summary:\n",
      "    ======================================\n",
      "    X_train: (36937, 2)\n",
      "    X_test: (4105, 2)\n",
      "    item_encode_train: (36937, 128)\n",
      "    item_encode_test: (4105, 128)\n",
      "    user_feature_train: (36937, 127)\n",
      "    user_features_test: (4105, 127)\n",
      "    ======================================\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# items related pipelines\n",
    "encoded_items, goods = preprocess_goods_live()\n",
    "goods, top_link_ids, top_user_ids = filter_goods_and_users(goods)\n",
    "ratings, user2id, item2id = make_rating_table(goods)\n",
    "id2user = {v:k for k,v in user2id.items()}\n",
    "id2item = {v:k for k,v in item2id.items()}\n",
    "\n",
    "# user related pipelines\n",
    "user_features, user_fans_df = load_user_features()\n",
    "user_features = userinfo_to_id(user_features,user_fans_df,user2id)\n",
    "\n",
    "# negative sampling ratings\n",
    "dataset = negative_sampling(ratings)\n",
    "\n",
    "# split and merge item and user data\n",
    "X_train, item_encode_train, user_feature_train, \\\n",
    "    X_test, item_encode_test, user_feature_test,\\\n",
    "    y_train, y_test = recommend_train_test_split(dataset, \n",
    "                                                 encoded_items, \n",
    "                                                 user_features, \n",
    "                                                 test_size = 0.1,\n",
    "                                                 shuffle = True)\n",
    "\n",
    "\n",
    "# model structure based on data\n",
    "model_params = dict(\n",
    "    n_users = ratings.user_id.nunique(),\n",
    "    n_items = ratings.item_id.nunique(),\n",
    "    item_feature_dim = item_encode_train.shape[1],\n",
    "    user_feature_dim = user_feature_train.shape[1],\n",
    "    embed_hidden_dim = 10,\n",
    "    reg = 0.\n",
    "    )\n",
    "\n",
    "# get the model\n",
    "model = get_recommend_model(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36937 samples, validate on 4105 samples\n",
      "Epoch 1/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0221 - accuracy: 0.9948 - val_loss: 0.5286 - val_accuracy: 0.9155\n",
      "Epoch 2/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0220 - accuracy: 0.9945 - val_loss: 0.5352 - val_accuracy: 0.9155\n",
      "Epoch 3/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0216 - accuracy: 0.9944 - val_loss: 0.5494 - val_accuracy: 0.9138\n",
      "Epoch 4/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0200 - accuracy: 0.9956 - val_loss: 0.5558 - val_accuracy: 0.9140\n",
      "Epoch 5/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0198 - accuracy: 0.9952 - val_loss: 0.5576 - val_accuracy: 0.9150\n",
      "Epoch 6/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0194 - accuracy: 0.9955 - val_loss: 0.5582 - val_accuracy: 0.9143\n",
      "Epoch 7/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0190 - accuracy: 0.9956 - val_loss: 0.5725 - val_accuracy: 0.9152\n",
      "Epoch 8/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0184 - accuracy: 0.9961 - val_loss: 0.5757 - val_accuracy: 0.9135\n",
      "Epoch 9/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0179 - accuracy: 0.9958 - val_loss: 0.5775 - val_accuracy: 0.9145\n",
      "Epoch 10/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0177 - accuracy: 0.9961 - val_loss: 0.5889 - val_accuracy: 0.9133\n",
      "Epoch 11/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0168 - accuracy: 0.9963 - val_loss: 0.5972 - val_accuracy: 0.9143\n",
      "Epoch 12/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0167 - accuracy: 0.9965 - val_loss: 0.5923 - val_accuracy: 0.9157\n",
      "Epoch 13/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0170 - accuracy: 0.9960 - val_loss: 0.6010 - val_accuracy: 0.9155\n",
      "Epoch 14/100\n",
      "36937/36937 [==============================] - 0s 6us/sample - loss: 0.0160 - accuracy: 0.9965 - val_loss: 0.6102 - val_accuracy: 0.9125\n",
      "Epoch 15/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0163 - accuracy: 0.9963 - val_loss: 0.6089 - val_accuracy: 0.9125\n",
      "Epoch 16/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0161 - accuracy: 0.9968 - val_loss: 0.6213 - val_accuracy: 0.9143\n",
      "Epoch 17/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0146 - accuracy: 0.9972 - val_loss: 0.6275 - val_accuracy: 0.9135\n",
      "Epoch 18/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0141 - accuracy: 0.9973 - val_loss: 0.6376 - val_accuracy: 0.9138\n",
      "Epoch 19/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0138 - accuracy: 0.9973 - val_loss: 0.6419 - val_accuracy: 0.9147\n",
      "Epoch 20/100\n",
      "36937/36937 [==============================] - 0s 6us/sample - loss: 0.0136 - accuracy: 0.9975 - val_loss: 0.6419 - val_accuracy: 0.9155\n",
      "Epoch 21/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0134 - accuracy: 0.9975 - val_loss: 0.6645 - val_accuracy: 0.9143\n",
      "Epoch 22/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0130 - accuracy: 0.9977 - val_loss: 0.6763 - val_accuracy: 0.9128\n",
      "Epoch 23/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0129 - accuracy: 0.9976 - val_loss: 0.6731 - val_accuracy: 0.9138\n",
      "Epoch 24/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0123 - accuracy: 0.9979 - val_loss: 0.6775 - val_accuracy: 0.9145\n",
      "Epoch 25/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0122 - accuracy: 0.9977 - val_loss: 0.6902 - val_accuracy: 0.9133\n",
      "Epoch 26/100\n",
      "36937/36937 [==============================] - 0s 6us/sample - loss: 0.0121 - accuracy: 0.9979 - val_loss: 0.6926 - val_accuracy: 0.9160\n",
      "Epoch 27/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0115 - accuracy: 0.9981 - val_loss: 0.7273 - val_accuracy: 0.9130\n",
      "Epoch 28/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0126 - accuracy: 0.9976 - val_loss: 0.7082 - val_accuracy: 0.9150\n",
      "Epoch 29/100\n",
      "36937/36937 [==============================] - 0s 6us/sample - loss: 0.0115 - accuracy: 0.9978 - val_loss: 0.7151 - val_accuracy: 0.9147\n",
      "Epoch 30/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0106 - accuracy: 0.9983 - val_loss: 0.7137 - val_accuracy: 0.9179\n",
      "Epoch 31/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0108 - accuracy: 0.9982 - val_loss: 0.7319 - val_accuracy: 0.9145\n",
      "Epoch 32/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0100 - accuracy: 0.9985 - val_loss: 0.7385 - val_accuracy: 0.9157\n",
      "Epoch 33/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0098 - accuracy: 0.9985 - val_loss: 0.7490 - val_accuracy: 0.9121\n",
      "Epoch 34/100\n",
      "36937/36937 [==============================] - 0s 6us/sample - loss: 0.0093 - accuracy: 0.9987 - val_loss: 0.7515 - val_accuracy: 0.9155\n",
      "Epoch 35/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0093 - accuracy: 0.9988 - val_loss: 0.7551 - val_accuracy: 0.9152\n",
      "Epoch 36/100\n",
      "36937/36937 [==============================] - 0s 6us/sample - loss: 0.0088 - accuracy: 0.9988 - val_loss: 0.7736 - val_accuracy: 0.9138\n",
      "Epoch 37/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0085 - accuracy: 0.9990 - val_loss: 0.7829 - val_accuracy: 0.9147\n",
      "Epoch 38/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0089 - accuracy: 0.9987 - val_loss: 0.7767 - val_accuracy: 0.9152\n",
      "Epoch 39/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0082 - accuracy: 0.9989 - val_loss: 0.7899 - val_accuracy: 0.9152\n",
      "Epoch 40/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0079 - accuracy: 0.9988 - val_loss: 0.7901 - val_accuracy: 0.9169\n",
      "Epoch 41/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0078 - accuracy: 0.9989 - val_loss: 0.8029 - val_accuracy: 0.9138\n",
      "Epoch 42/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0075 - accuracy: 0.9991 - val_loss: 0.7959 - val_accuracy: 0.9167\n",
      "Epoch 43/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0073 - accuracy: 0.9991 - val_loss: 0.8062 - val_accuracy: 0.9160\n",
      "Epoch 44/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0070 - accuracy: 0.9993 - val_loss: 0.8178 - val_accuracy: 0.9162\n",
      "Epoch 45/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0070 - accuracy: 0.9992 - val_loss: 0.8382 - val_accuracy: 0.9157\n",
      "Epoch 46/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.8497 - val_accuracy: 0.9133\n",
      "Epoch 47/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0073 - accuracy: 0.9991 - val_loss: 0.8414 - val_accuracy: 0.9157\n",
      "Epoch 48/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0069 - accuracy: 0.9991 - val_loss: 0.8438 - val_accuracy: 0.9167\n",
      "Epoch 49/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0065 - accuracy: 0.9991 - val_loss: 0.8595 - val_accuracy: 0.9150\n",
      "Epoch 50/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0060 - accuracy: 0.9994 - val_loss: 0.8647 - val_accuracy: 0.9155\n",
      "Epoch 51/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0059 - accuracy: 0.9994 - val_loss: 0.8733 - val_accuracy: 0.9143\n",
      "Epoch 52/100\n",
      "36937/36937 [==============================] - 0s 6us/sample - loss: 0.0057 - accuracy: 0.9994 - val_loss: 0.8919 - val_accuracy: 0.9143\n",
      "Epoch 53/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0056 - accuracy: 0.9995 - val_loss: 0.8860 - val_accuracy: 0.9152\n",
      "Epoch 54/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0054 - accuracy: 0.9995 - val_loss: 0.8873 - val_accuracy: 0.9155\n",
      "Epoch 55/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0061 - accuracy: 0.9992 - val_loss: 0.9071 - val_accuracy: 0.9143\n",
      "Epoch 56/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0054 - accuracy: 0.9995 - val_loss: 0.9108 - val_accuracy: 0.9135\n",
      "Epoch 57/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0049 - accuracy: 0.9995 - val_loss: 0.9235 - val_accuracy: 0.9143\n",
      "Epoch 58/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0047 - accuracy: 0.9996 - val_loss: 0.9217 - val_accuracy: 0.9147\n",
      "Epoch 59/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.9273 - val_accuracy: 0.9155\n",
      "Epoch 60/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0051 - accuracy: 0.9993 - val_loss: 0.9581 - val_accuracy: 0.9128\n",
      "Epoch 61/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0044 - accuracy: 0.9996 - val_loss: 0.9452 - val_accuracy: 0.9143\n",
      "Epoch 62/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0042 - accuracy: 0.9996 - val_loss: 0.9565 - val_accuracy: 0.9140\n",
      "Epoch 63/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0043 - accuracy: 0.9995 - val_loss: 0.9545 - val_accuracy: 0.9157\n",
      "Epoch 64/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0042 - accuracy: 0.9997 - val_loss: 0.9790 - val_accuracy: 0.9133\n",
      "Epoch 65/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0039 - accuracy: 0.9998 - val_loss: 0.9780 - val_accuracy: 0.9135\n",
      "Epoch 66/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.9786 - val_accuracy: 0.9147\n",
      "Epoch 67/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0036 - accuracy: 0.9998 - val_loss: 0.9948 - val_accuracy: 0.9143\n",
      "Epoch 68/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0037 - accuracy: 0.9997 - val_loss: 0.9981 - val_accuracy: 0.9138\n",
      "Epoch 69/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.9940 - val_accuracy: 0.9155\n",
      "Epoch 70/100\n",
      "36937/36937 [==============================] - 0s 6us/sample - loss: 0.0034 - accuracy: 0.9997 - val_loss: 1.0230 - val_accuracy: 0.9138\n",
      "Epoch 71/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0033 - accuracy: 0.9998 - val_loss: 1.0117 - val_accuracy: 0.9143\n",
      "Epoch 72/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0033 - accuracy: 0.9998 - val_loss: 1.0354 - val_accuracy: 0.9130\n",
      "Epoch 73/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0031 - accuracy: 0.9998 - val_loss: 1.0379 - val_accuracy: 0.9140\n",
      "Epoch 74/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0029 - accuracy: 0.9998 - val_loss: 1.0451 - val_accuracy: 0.9145\n",
      "Epoch 75/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0029 - accuracy: 0.9998 - val_loss: 1.0496 - val_accuracy: 0.9138\n",
      "Epoch 76/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0028 - accuracy: 0.9998 - val_loss: 1.0628 - val_accuracy: 0.9135\n",
      "Epoch 77/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0027 - accuracy: 0.9998 - val_loss: 1.0751 - val_accuracy: 0.9143\n",
      "Epoch 78/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0026 - accuracy: 0.9999 - val_loss: 1.0810 - val_accuracy: 0.9135\n",
      "Epoch 79/100\n",
      "36937/36937 [==============================] - 0s 6us/sample - loss: 0.0027 - accuracy: 0.9998 - val_loss: 1.0860 - val_accuracy: 0.9145\n",
      "Epoch 80/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0027 - accuracy: 0.9998 - val_loss: 1.1006 - val_accuracy: 0.9123\n",
      "Epoch 81/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0028 - accuracy: 0.9998 - val_loss: 1.0869 - val_accuracy: 0.9157\n",
      "Epoch 82/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0023 - accuracy: 0.9998 - val_loss: 1.1140 - val_accuracy: 0.9133\n",
      "Epoch 83/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0023 - accuracy: 0.9998 - val_loss: 1.1007 - val_accuracy: 0.9157\n",
      "Epoch 84/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0022 - accuracy: 0.9999 - val_loss: 1.1325 - val_accuracy: 0.9135\n",
      "Epoch 85/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0021 - accuracy: 0.9999 - val_loss: 1.1268 - val_accuracy: 0.9155\n",
      "Epoch 86/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0019 - accuracy: 0.9999 - val_loss: 1.1376 - val_accuracy: 0.9155\n",
      "Epoch 87/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0019 - accuracy: 0.9999 - val_loss: 1.1456 - val_accuracy: 0.9155\n",
      "Epoch 88/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0018 - accuracy: 0.9999 - val_loss: 1.1465 - val_accuracy: 0.9155\n",
      "Epoch 89/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0017 - accuracy: 0.9999 - val_loss: 1.1450 - val_accuracy: 0.9152\n",
      "Epoch 90/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0016 - accuracy: 0.9999 - val_loss: 1.1654 - val_accuracy: 0.9155\n",
      "Epoch 91/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0016 - accuracy: 0.9999 - val_loss: 1.1674 - val_accuracy: 0.9147\n",
      "Epoch 92/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0016 - accuracy: 0.9999 - val_loss: 1.1794 - val_accuracy: 0.9157\n",
      "Epoch 93/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0016 - accuracy: 0.9999 - val_loss: 1.1899 - val_accuracy: 0.9150\n",
      "Epoch 94/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0015 - accuracy: 0.9999 - val_loss: 1.1870 - val_accuracy: 0.9150\n",
      "Epoch 95/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0014 - accuracy: 0.9999 - val_loss: 1.2123 - val_accuracy: 0.9135\n",
      "Epoch 96/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0014 - accuracy: 0.9999 - val_loss: 1.2175 - val_accuracy: 0.9140\n",
      "Epoch 97/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0014 - accuracy: 0.9999 - val_loss: 1.2203 - val_accuracy: 0.9143\n",
      "Epoch 98/100\n",
      "36937/36937 [==============================] - 0s 5us/sample - loss: 0.0016 - accuracy: 0.9999 - val_loss: 1.2160 - val_accuracy: 0.9143\n",
      "Epoch 99/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0013 - accuracy: 0.9999 - val_loss: 1.2281 - val_accuracy: 0.9143\n",
      "Epoch 100/100\n",
      "36937/36937 [==============================] - 0s 4us/sample - loss: 0.0013 - accuracy: 0.9999 - val_loss: 1.2468 - val_accuracy: 0.9138\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "history = model.fit(x = [X_train.user_id.values,X_train.item_id.values,item_encode_train,user_feature_train.values],y = y_train.values,\n",
    "                   epochs = EPOCHS,\n",
    "                   batch_size = 1024,\n",
    "                   validation_data = (\n",
    "                   [X_test.user_id.values,X_test.item_id.values,item_encode_test,user_feature_test], y_test.values)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAEICAYAAAD8yyfzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGZBJREFUeJzt3XmYVNWZx/Hv2xuooFGQxWZVQMdoRIO44hYXcAESjSIu4OiDG6PGLSoOGmJ8YjIa4wyjwWhUjBKXUVE2dxOSGLtdogFBWkBoFoFmMa50V73zRxWd6qapqobqU9WX34fnPPa999S5b2Hz9tvnnrrX3B0REQmjKN8BiIhsT5R0RUQCUtIVEQlISVdEJCAlXRGRgJR0RUQCUtKVema2g5k9b2YbzOzJbRjnHDN7MZex5YOZzTCzUfmOQ6JFSbcVMrORZlZpZp+b2YpkcjgyB0OfAXQGOrj7D7d2EHf/vbufmIN4GjCzY8zMzeyZRvsPSO5/PctxbjWzRzP1c/ch7v7wVoYr0iQl3VbGzK4G7gZuJ5EgewD/CwzLwfA9gY/cvS4HY7WU1cBhZtYhZd8o4KNcncAS9G9DWoa7q7WSBuwCfA78ME2fNiSS8vJkuxtokzx2DFANXAOsAlYAFySP/QTYCNQmz3EhcCvwaMrYvQAHSpLbo4GFwD+BRcA5Kftnp7zucKAC2JD87+Epx14Hfgr8OTnOi0DHLby3TfHfB1ye3FcMLAPGA6+n9P01sBT4DHgbGJTcP7jR+/x7Shw/S8bxFdAnue+i5PF7gadTxr8DeAWwfH9fqLWupp/mrcthQFvgmTR9xgGHAv2BA4CBwM0px7uQSN7lJBLrRDPb1d1vIVE9/8Hd27n7A+kCMbOdgHuAIe7enkRifa+JfrsB05J9OwB3AdMaVaojgQuATkAZcG26cwOPAOcnvz4J+AeJHzCpKkj8HewGPAY8aWZt3X1mo/d5QMprzgPGAO2BTxqNdw2wv5mNNrNBJP7uRrm7PkcvzaKk27p0ANZ4+l//zwEmuPsqd19NooI9L+V4bfJ4rbtPJ1Ht7b2V8cSB/cxsB3df4e5zmuhzCrDA3Se7e527Pw7MA05L6fM7d//I3b8CniCRLLfI3f8C7GZme5NIvo800edRd69JnvNOEr8BZHqfD7n7nORrahuN9yWJv8e7gEeB/3D36gzjiWxGSbd1qQE6mllJmj570LBK+yS5r36MRkn7S6BdcwNx9y+As4BLgBVmNs3M9skink0xladsr9yKeCYDY4FjaaLyN7NrzezD5EqM9SSq+44Zxlya7qC7/43EdIqR+OEg0mxKuq3LX4FvgOFp+iwncUFskx5s/qt3tr4AdkzZ7pJ60N1nufsJQFcS1ev9WcSzKaZlWxnTJpOBy4DpySq0XvLX/+uBM4Fd3f1bJOaTbVPoWxgz7VSBmV1OomJenhxfpNmUdFsRd99A4oLRRDMbbmY7mlmpmQ0xs18kuz0O3Gxmu5tZx2T/jMujtuA94Cgz62FmuwA3bjpgZp3NbFhybvcbEtMU8SbGmA70Sy5zKzGzs4B9gRe2MiYA3H0RcDSJOezG2gN1JFY6lJjZeGDnlOOfAr2as0LBzPoBtwHnkphmuN7M0k6DiDRFSbeVSc5PXk3i4thqEr8SjwWeTXa5DagE3gc+AN5J7tuac70E/CE51ts0TJRFyTiWA2tJJMBLmxijBjiVxIWoGhIV4qnuvmZrYmo09mx3b6qKnwXMJLGM7BPgaxpOHWz64EeNmb2T6TzJ6ZxHgTvc/e/uvgC4CZhsZm225T3I9sd08VVEJBxVuiIiASnpiogEpKQrIhKQkq6ISEDpFtnnRO2ahbpSJ5vp3PukfIcgBWjtPxdY5l7pNSfnlHbcc5vP11yqdEVEAmrxSldEJKh4LN8RpKWkKyLREivk20Er6YpIxLg39Wn0wqGkKyLRElfSFREJR5WuiEhAupAmIhKQKl0RkXBcqxdERALShTQRkYA0vSAiEpAupImIBKRKV0QkIF1IExEJSBfSRETCcdecrohIOJrTFREJSNMLIiIBqdIVEQkoVpvvCNJS0hWRaNH0gohIQJpeEBEJSJWuiEhASroiIuG4LqSJiASkOV0RkYA0vSAiEpAqXRGRgFTpiogEpEpXRCSgOt3EXEQknAKvdIvyHYCISE7F49m3DMxssJnNN7MqM7uhieOjzWy1mb2XbBdlGlOVrohES44qXTMrBiYCJwDVQIWZTXX3uY26/sHdx2Y7rpKuiERL7lYvDASq3H0hgJlNAYYBjZNus2h6QUSixeNZNzMbY2aVKW1MykjlwNKU7erkvsZON7P3zewpM+ueKTxVuiISLc1YveDuk4BJ23C254HH3f0bM7sYeBg4Lt0LVOmKSLS4Z9/SWwakVq7dkvtSTuU17v5NcvO3wHczDaqkKyLRkrvVCxVAXzPrbWZlwAhgamoHM+uasjkU+DDToJpeEJFoydGFNHevM7OxwCygGHjQ3eeY2QSg0t2nAleY2VCgDlgLjM40rpKuiERLDj8c4e7TgemN9o1P+fpG4MbmjKmkKyLREovlO4K0lHRFJFp0lzERkYCUdEVEAirwG94o6YpIpHg84/rbvFLSFZFo0fSCiEhAWr0gIhKQKl0RkYAKPOnq3gs5MvvNSk4dcRFDzvx3fjv5ic2OPzvtJQadchanj7qc00ddzlNTZ9Yfu+t/H2D4uZcw/NxLmPHyGyHDlhz73vGD+Ns7s6h872WuvHrMZsfLysp44KG7qXzvZV569Sm690jcKbB7j3KWrfqAN/48lTf+PJU7755Q/5rS0lJ+dc9PeevdF3nz7ZmcNvSkYO+nVcrdDW9ahCrdHIjFYtx250Tuv/t2unTqyFkXXcmxRx7CXr17Nug3+LijGXfNZQ32vfGXt5g7/2OeemgiG2truWDs9Qw6bADtdtop5FuQHCgqKuIXd97KD4aNZvmylbzyxtPMnPYq8+dX1fc59/wzWL/+Mwb0P54fnH4Kt064jgtHXwXA4kVLOPqIoZuNe811l7J69VoGHngiZsauu30r2HtqlVp7pWtm+5jZj83snmT7sZn9W4jgWosPPvyIHt32oHt5V0pLSxnyvaN59U9vZvXajxctYUD//SgpKWbHHdrSr09vZr/5dgtHLC3huwO+w6KFn/DJ4qXU1tbyf09PY8ip32vQ5+RTjmfKY/8HwHPPzuSoYw7LOO45553B3XfeB4C7s7ZmXe6Dj5K4Z9/yIG3SNbMfA1MAA95KNgMeb+ohbdurVavX0KXT7vXbnTt1ZNXqms36vfTGbL5//qX8aNxtrPh0NQB79+nN7L+9zVdff8269RuoeOd9Vq5aHSx2yZ2uXbuwbNmK+u3ly1bStWvnhn326Myy6pVA4jekzzZ8zm4ddgWgR89uvD77OZ6f8XsOPXwAADvv0h6Am/7zKl7707P87pF72H33DiHeTusVi2Xf8iBTpXshcLC7/9zdH022n5N4dtCFW3pR6iMwfvvI47mMt9U65shDePGph3jmkXs57OCDGHfbnQAccch3GXTYAM69+Bquu+UODvj2PhQXaap9e/PpytV8Z9+jOebIYdx84+3c/8BdtG/fjpKSEsq7deWtN9/l2EHDqXjrXSb8TPVOOh6PZ93yIdO/7jiwRxP7uyaPNcndJ7n7AHcfcNH5Z29LfK1Cp907NqhOP121hk6NqpFv7bIzZWVlAJx+2knMnb+g/tjFo87m6Ycn8ttf344DPbs39RgmKXQrVqykvPxf97Teo7wLK1Z82rDP8k8p79YFgOLiYnbepR1ra9axceNG1q1dD8Df35vDokVL2KtPL9bWrOOLL77k+amzAHjumRkc0P/bgd5RK9WapxeAq4BXzGyGmU1KtpnAK8CVLR9e67DfPv1YUr2c6uUrqa2tZcYrb3DskYc26LN6zdr6r1+b/SZ79kw8BSQWi7F+w2cAzK9axEdVizh8YMYnfkgBeuftD9hzr1706NmN0tJSfnD6Kcyc9kqDPjOmv8KIkT8AYNjwwfzpjcTcf4eOu1GU/A2nZ6/u7LlXTxYvTjwTcdaMVzly0CEAHHXM4cyfV4Wk0YwHU+ZD2tUL7j7TzPqRmE7YVH4tAyrcvbA/9hFQSUkxN/3oUi6++mZisRjfP/VE+uzZk/+5/xG+vU8/jh10KI8++Ryvz36T4pJidmnfnttuvgaAuroY5192LQDtdtyRn4+/jpKS4ny+HdlKsViM66/9CU89+yDFRcX8fvJTzJtXxY3jruTddz9g5vRXefSRJ7nv/v+i8r2XWbduPRdd8CMADj/8YG68+Upqa+uIx+Ncc9UtrF+3AYBbx/+S++7/L26/Yxxr1qxl7KWaXkirwO+9YN7Ca9Vq1yws7L8ByYvOvbXWVDa39p8LbFvH+GL8iKxzzk4Tpmzz+ZpL63RFJFp0a0cRkYAKfHpBSVdEIiVfS8GypaQrItGiSldEJCAlXRGRgHQTcxGRcPSMNBGRkJR0RUQC0uoFEZGAVOmKiARU4ElXN24VkUjxWDzrlomZDTaz+WZWle7BDWZ2upm5mQ3INKYqXRGJlhxVumZWDEwETgCqgQozm+rucxv1a0/iVrd/y2ZcVboiEike96xbBgOBKndf6O4bSTy6bFgT/X4K3AF8nU18SroiEi25e3JEObA0Zbuaf91XHAAzOwjo7u7Tsg1PSVdEoiWefUt9nmOyjcn2NGZWBNwFXNOc8DSnKyKR4nXZr9N190nApC0cXgZ0T9nulty3SXtgP+B1MwPoAkw1s6HuXrmlcyrpiki05O6zERVAXzPrTSLZjgBGbjro7huAjpu2zex14Np0CReUdEUkYnJ17wV3rzOzscAsoBh40N3nmNkEoNLdp27NuEq6IhItOfwUsLtPB6Y32jd+C32PyWZMJV0RiRTdZUxEJKTCvt+Nkq6IRIvX5TuC9JR0RSRSCvwJ7Eq6IhIxSroiIuGo0hURCUhJV0QkII9ZvkNIS0lXRCJFla6ISEAeV6UrIhKMKl0RkYDcVemKiASjSldEJKC4Vi+IiISjC2kiIgEp6YqIBOSFfTtdJV0RiRZVuiIiAWnJmIhIQDGtXhARCUeVrohIQJrTFREJSKsXREQCUqUrIhJQLF6U7xDSUtIVkUjR9IKISEBxrV4QEQlHS8ZERALa7qcXdthjUEufQlqhd8sPyncIElGFPr1Q2Jf5RESaKRYvyrplYmaDzWy+mVWZ2Q1NHL/EzD4ws/fMbLaZ7ZtpTCVdEYkUb0ZLx8yKgYnAEGBf4Owmkupj7r6/u/cHfgHclSk+zemKSKTkcHphIFDl7gsBzGwKMAyYu6mDu3+W0n8nMudyJV0RiZbmrF4wszHAmJRdk9x9UvLrcmBpyrFq4JAmxrgcuBooA47LdE4lXRGJlOY8DDiZYCdl7Jh+jInARDMbCdwMjErXX3O6IhIpjmXdMlgGdE/Z7pbctyVTgOGZBlXSFZFIqXPLumVQAfQ1s95mVgaMAKamdjCzvimbpwALMg2q6QURiZQsKtjsxnGvM7OxwCygGHjQ3eeY2QSg0t2nAmPN7HigFlhHhqkFUNIVkYhpzpxuJu4+HZjeaN/4lK+vbO6YSroiEim5qnRbipKuiERKLivdlqCkKyKRElOlKyISToE/rUdJV0SiJa5KV0QknAK/na6SrohEiy6kiYgEFDdNL4iIBBPLdwAZKOmKSKRo9YKISEBavSAiEpBWL4iIBKTpBRGRgLRkTEQkoJgqXRGRcFTpiogEpKQrIhJQM57AnhdKuiISKap0RUQC0seARUQC0jpdEZGANL0gIhKQkq6ISEC694KISECa0xURCUirF0REAooX+ASDkq6IRIoupImIBFTYda6SrohETKFXukX5DkBEJJfqzLNumZjZYDObb2ZVZnZDE8evNrO5Zva+mb1iZj0zjamkKyKR4s1o6ZhZMTARGALsC5xtZvs26vYuMMDdvwM8BfwiU3xKuiISKfFmtAwGAlXuvtDdNwJTgGGpHdz9NXf/Mrn5JtAt06BKuiISKXE862ZmY8ysMqWNSRmqHFiasl2d3LclFwIzMsWnC2kiEinNWb3g7pOASdt6TjM7FxgAHJ2pr5KuiERKDlcvLAO6p2x3S+5rwMyOB8YBR7v7N5kGVdIVkUiJ5W6lbgXQ18x6k0i2I4CRqR3M7EDgN8Bgd1+VzaBKuiISKbmqdN29zszGArOAYuBBd59jZhOASnefCvwSaAc8aWYAS9x9aLpxlXRFJFI8h59Jc/fpwPRG+8anfH18c8dU0hWRSNEn0rYTJ514DHP+8UfmzZ3N9dddvtnxsrIyHvv9vcybO5u/zH6enj0Ty/kOHtCfyooXqax4kbcrX2LYsMGhQ5cW1O6og+j3yr30e+037H7JGZsd323kYPrO+G/6TPs1ez5xB236JK7btDuyP32m/ipxbOqv2Omw74QOvdVqzpKxfDD3lj1xSVl5od9/YpsVFRXx4Zw/Mfjks6muXsGbf53OueddxocfLqjvc8nFo9h//3/j8rE3cOaZQxk+bAgjz7mUHXZoy8aNtcRiMbp06cQ7lS/RvedBxGKFflfQbfNu+UH5DqHlFRXR79X7WHTef1K3soa9nruLpVf8km+q/rX0s6jdDsQ//wqA9scPpMO5J7N49K203XdP6tasp27VWtr060Hvhycw77DReXoj4ey/6PltvgX5pb3OzDrn3Lv4ieC3PFelmwMDDz6Qjz9ezKJFS6itreWJJ55j6GknNegz9LQTmTz5SQCefnoaxx17JABfffV1fYJt27YNLf1DUMLZ8YC+bPxkBbVLP8Vr69jw/B/Z+YRDGvTZlHABinZoW7/I9Ou5C6lbtRaAbz5agrUtw8o0G5iNOjzrlg/6v5gDe5R3YWn18vrt6mUrGHjwgVvsE4vF2LDhMzp02JWamnUMPPhA7r//Tnr26MaoC66IfJW7vSjp0oHaFWvqt2tX1rBj/36b9dvtvJPpeOFwrLSEReeM2+z4zkMO5+t/fIxvrGvReKMilxfSWsJWV7pmdkGaY/UfrYvHv9jaU2w33qp4lwP6H8ehh5/MDdePpU2bNvkOSQJaO3k6Hx0zhpV3PEynsWc1ONambw+6/Hg0y8ZNzFN0rU8O773QIrZleuEnWzrg7pPcfYC7Dygq2mkbTtE6LF+2ku7d9qjf7lbeleXLV26xT3FxMbvssjM1Nesa9Jk3r4rPP/+S/b69d8sHLS2ubmUNpV071m+XdulA7cqaLfZPTD8cWr9d0qUDPX9zE9XX/IqNS1Zu8XXSkDfjTz6kTbrJe0Q21T4AOgeKseBVVL5Hnz696dWrO6WlpZx55jCef+HFBn2ef+FFzjvvhwCcfvopvPb6nwHo1as7xcXFAPToUc7ee+/F4k+WIq3fl+8voE2vPSjt1hkrLWGX047is5ffatCnrFfX+q/bHzeAbxYnpqCK2u9ErwdvYeUdD/Pl2x8Gjbu1K/RKN9OcbmfgJGBdo/0G/KVFImqFYrEYV151M9OnPUZxUREPPfwH5s79iFtvuZbKt//OCy+8xIO/m8LDD93DvLmzWbduPSPPvQyAI44YyPXXXU5tbR3xeJyxV9y0WQUsrVQszvJb7qP3Iz+BoiLWPfky3yxYQqcfncNXHyzgny+/RYfzT6XdEf3xujpiGz6n+tq7Aegw6hTa9OxKpytG0OmKEQAsOn88sZoN+XxHrUKswC9Gp10yZmYPAL9z99lNHHvM3Uc28bIGtoclY9J828WSMWm2XCwZG9nz+1nnnMc+eSb4krG0la67X5jmWMaEKyISWqGvXtCSMRGJlEL/GLCSrohESr4+3pstJV0RiRRNL4iIBFToqxeUdEUkUjS9ICISkC6kiYgEpDldEZGANL0gIhJQod+TWklXRCIlh49gbxFKuiISKZpeEBEJSNMLIiIBqdIVEQlIS8ZERALSx4BFRALS9IKISEBKuiIiAWn1gohIQIVe6aZ9BLuISGvjzfiTiZkNNrP5ZlZlZjc0cfwoM3vHzOrM7Ixs4lOlKyKREvPc3NzRzIqBicAJQDVQYWZT3X1uSrclwGjg2mzHVdIVkUjJ4ZzuQKDK3RcCmNkUYBhQn3TdfXHyWNaZXtMLIhIpcTzrZmZjzKwypY1JGaocWJqyXZ3ct01U6YpIpDTnE2nuPgmY1HLRbE5JV0QiJZ676YVlQPeU7W7JfdtE0wsiEik5XL1QAfQ1s95mVgaMAKZua3xKuiISKTGPZ93Scfc6YCwwC/gQeMLd55jZBDMbCmBmB5tZNfBD4DdmNidTfJpeEJFIyeH0Au4+HZjeaN/4lK8rSEw7ZE1JV0QiRbd2FBEJKJeVbktQ0hWRSFGlKyISUMxj+Q4hLSVdEYkU3dpRRCSgQr+1o5KuiESKKl0RkYC0ekFEJCCtXhARCShXNzFvKUq6IhIpmtMVEQlIc7oiIgGp0hURCUjrdEVEAlKlKyISkFYviIgEpAtpIiIBaXpBRCQgfSJNRCQgVboiIgEV+pyuFfpPhSgxszHuPinfcUhh0ffF9qUo3wFsZ8bkOwApSPq+2I4o6YqIBKSkKyISkJJuWJq3k6bo+2I7ogtpIiIBqdIVEQlISVdEJCAl3UDMbLCZzTezKjO7Id/xSP6Z2YNmtsrM/pHvWCQcJd0AzKwYmAgMAfYFzjazffMblRSAh4DB+Q5CwlLSDWMgUOXuC919IzAFGJbnmCTP3P2PwNp8xyFhKemGUQ4sTdmuTu4Tke2Mkq6ISEBKumEsA7qnbHdL7hOR7YySbhgVQF8z621mZcAIYGqeYxKRPFDSDcDd64CxwCzgQ+AJd5+T36gk38zsceCvwN5mVm1mF+Y7Jml5+hiwiEhAqnRFRAJS0hURCUhJV0QkICVdEZGAlHRFRAJS0hURCUhJV0QkoP8HRVLWGS+OY5cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9137637028014617\n",
      "Auc score: 0.913873756344095\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, X_test, item_encode_test, user_feature_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommends():\n",
    "    all_items = set(ratings.item_id.unique())\n",
    "    user = np.random.choice(X_test.user_id.values)\n",
    "    user = np.repeat([user],len(all_items))  \n",
    "\n",
    "    recos = np.argsort(model.predict([user, np.array(list(all_items)),encoded_items[list(all_items),],user_features.iloc[user].values]).flatten())[::-1][:30]\n",
    "    goods[goods['id'] == id2user[user[0]]]\n",
    "\n",
    "    print('Recommendation List:\\n')\n",
    "    for i, reco in enumerate(recos):\n",
    "        print('No {}, Item: {}'.format(i+1,goods[goods.link_id == id2item[reco]]['name'].iloc[0]))\n",
    "\n",
    "    print('\\n\\nKnown positive:\\n')\n",
    "    for i, good in enumerate(goods[goods['id'] == id2user[user[0]]]['name'].unique().tolist()):\n",
    "        print('No {}, Item: {}'.format(i, good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendation List:\n",
      "\n",
      "No 1, Item: 实木衣架子衣挂家用挂衣架服装店专用防滑无痕木质衣服撑子挂钩\n",
      "No 2, Item: 2月产蒙牛小真果粒饮品可爱萌mini小包儿童牛奶风味125ml*20盒\n",
      "No 3, Item: 只投螺碗螺蛳粉柳州正宗包邮螺丝粉320g*5袋螺狮粉酸辣粉方便面条\n",
      "No 4, Item: 为美兹蛋黄酥芝士流心奶黄酥6枚 夹心馅美食糕点早餐小吃零食品\n",
      "No 5, Item: 水果坚果燕麦片营养早餐即食冲饮酸奶果粒代餐粥饱腹速食懒人食品\n",
      "No 6, Item: 龙王豆浆粉商用速溶冲饮原味家用黑豆黄豆打豆浆早餐30g*16小包装\n",
      "No 7, Item: 爱民螺蛳粉柳州正宗方便速食袋装香辣螺狮粉广西特产美食现货包邮\n",
      "No 8, Item: 嗨吃家酸辣粉6桶装网红桶装整箱即食方面速食红薯粉丝米线旗舰店\n",
      "No 9, Item: 贤合庄陈赫推荐网红自热火锅懒人自煮小火锅即食自助方便速食麻辣\n",
      "No 10, Item: 苹果x钢化膜11promax全屏iPhoneX覆盖11pro/7/8/8Plus手机se2贴膜iPhone xs防窥iPhonexr/xsmax防窥膜xr/6s/6\n",
      "No 11, Item: 靓涤垃圾袋家用手提式加厚实惠装一次性黑色背心拉圾桶塑料袋大号\n",
      "No 12, Item: 章丘铁锅手工老式炒锅无涂层不粘锅家用炒菜锅电磁炉煤气灶专用锅\n",
      "No 13, Item: 婴儿宝宝辅食锅煎蒸煮一体多功能麦饭石不粘锅儿童煮粥小奶锅炖锅\n",
      "No 14, Item: 麦饭石不粘锅炒锅铁锅家用炒菜锅电磁炉煎炒两用平底锅煤气灶专用\n",
      "No 15, Item: 颈椎按摩器家用电动智能护颈仪脖子按摩神器脉冲里疗肩颈部按摩仪\n",
      "No 16, Item: 林家铺子【冰糖黄桃罐头200g*4罐】儿童水果罐头即食蒸制零食整箱\n",
      "No 17, Item: 居家家杂物收纳盒3件套桌面化妆品储物收纳筐家用塑料厨房整理盒\n",
      "No 18, Item: 卜珂麦丽素桶装怀旧黑巧克力夹心麦芽脆心球零食朱古力糖果送儿童\n",
      "No 19, Item: 掌记咸蛋黄拌面116g*5袋装越南风味方便面泡面火鸡面带酱料包\n",
      "No 20, Item: 原味乳酸菌饮品340mlx12瓶养胃风味酸牛奶动力儿童饮料整箱益生元\n",
      "No 21, Item: 藤壶岛芝麻夹心海苔脆儿童即食海苔夹心脆海苔宝宝儿童零食罐装\n",
      "No 22, Item: Catfour咖啡蓝山风味咖啡三合一咖啡速溶黑咖啡粉饮品袋装40条杯\n",
      "No 23, Item: 美的布谷便携式榨汁机家用水果小型炸果汁机迷你电动杯型榨汁杯\n",
      "No 24, Item: 地漏防臭器卫生间下水道硅胶芯圆形浴室洗衣机盖味不锈钢内芯神器\n",
      "No 25, Item: 四川乐山钵钵鸡调料商用配方冷串串盆火锅麻辣烫底料包冷锅串串香\n",
      "No 26, Item: 无线蓝牙耳机双耳迷你适用iphone小米vivo华为oppo苹果安卓通用hs\n",
      "No 27, Item: 李子柒螺蛳粉广西特产柳州螺丝粉速食方便面米线螺狮粉3袋装\n",
      "No 28, Item: 玛呖德紫米面包全麦代餐夹心奶酪味吐司蛋糕点营养早餐零食品整箱\n",
      "No 29, Item: 李子柒桂花坚果藕粉纯藕粉坚果羹营养早餐特产代餐食品方便速食\n",
      "No 30, Item: 10包聪妈抽纸整箱9.9包邮特价纸巾批发面巾纸家用餐巾纸擦手纸抽\n",
      "\n",
      "\n",
      "Known positive:\n",
      "\n",
      "No 0, Item: 麦饭石不粘锅炒锅铁锅多功能炒菜锅电磁炉平底锅家用燃气灶适用锅\n",
      "No 1, Item: 小熊宿舍学生小锅多功能家用火锅煮面电煮锅寝室用一体迷你小电锅\n",
      "No 2, Item: 水果坚果燕麦片营养早餐即食冲饮酸奶果粒代餐粥饱腹速食懒人食品\n",
      "No 3, Item: 【大希地】原肉整切10片牛排牛扒套餐（眼肉牛排+西冷牛排）\n",
      "No 4, Item: 李子柒海鸭蛋黄酱流沙咸蛋黄酱酱拌饭酱拌面沙拉吐司酱80g*2瓶\n",
      "No 5, Item: 李子柒桂花坚果藕粉纯藕粉坚果羹营养早餐特产代餐食品方便速食\n",
      "No 6, Item: 大号浴巾成人比纯棉全棉吸水家用男女儿童不掉毛速干可爱毛巾裹巾\n",
      "No 7, Item: 森庄农品白凉粉家用做果冻的白凉粉儿果冻食用自制儿童专用粉500g\n",
      "No 8, Item: 嗨吃家酸辣粉6桶装网红桶装整箱即食方面速食红薯粉丝米线旗舰店\n",
      "No 9, Item: 4月蒙牛真果粒mini小包饮料125ml/盒装整箱好食期学生风味牛奶\n",
      "No 10, Item: 果真心麦片水果坚果燕麦片早餐即食酸奶果粒懒人代餐速食饱腹食品\n",
      "No 11, Item: 左道榨汁机 家用 水果小型便携式多功能迷你炸果汁机全自动榨汁杯\n",
      "No 12, Item: 卜珂麦丽素桶装怀旧黑巧克力夹心麦芽脆心球零食朱古力糖果送儿童\n",
      "No 13, Item: 为美兹蛋黄酥芝士流心奶黄酥6枚 夹心馅美食糕点早餐小吃零食品\n",
      "No 14, Item: 贤合庄陈赫推荐网红自热火锅懒人自煮小火锅即食自助方便速食麻辣\n",
      "No 15, Item: 浴巾家用成人男女士沐洗澡比纯棉全棉吸水速干不掉毛超大款号裹巾\n",
      "No 16, Item: 林家铺子【冰糖黄桃罐头200g*4罐】儿童水果罐头即食蒸制零食整箱\n",
      "No 17, Item: 【10碗】荞歌碗托 山西特产小吃碗团柳林荞面碗秃即食速食凉皮\n",
      "No 18, Item: 东北正宗烤冷面皮片真空包邮家用早餐手抓饼烤冷面家庭装带酱美食\n",
      "No 19, Item: 白凉粉家用做果冻的白凉粉儿果冻食用自制儿童专用粉烧仙草粉500g\n",
      "No 20, Item: 李子柒螺蛳粉广西特产柳州螺丝粉速食方便面米线螺狮粉3袋装\n",
      "No 21, Item: 李子柒紫薯蒸米糕夹心甜点休闲零食特产发糕早餐面包糕点540g/盒\n"
     ]
    }
   ],
   "source": [
    "generate_recommends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
